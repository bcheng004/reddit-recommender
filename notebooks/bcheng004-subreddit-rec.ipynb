{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import warnings \n",
        "warnings.simplefilter(action='ignore')\n",
        "!python --version"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Python 3.6.9 :: Anaconda, Inc.\r\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1639895033141
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\n",
        "dependencies:\n",
        "    - python=3.6.9\n",
        "    - numpy=1.18.*\n",
        "    - pandas=0.25.*\n",
        "    - pip:\n",
        "        - azureml-defaults==1.34.0\n",
        "        - confuse==1.6.0\n",
        "        - icecream==2.1.1\n",
        "        - plotly==5.3.1\n",
        "        - scikit-surprise==1.1.1\n",
        "        - kaggle==1.5.12"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting conda_dependencies.yml\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "confuse==1.6.0\n",
        "icecream==2.1.1\n",
        "plotly==5.3.1\n",
        "kaleido==0.2.1\n",
        "scikit-surprise==1.1.1\n",
        "kaggle==1.5.12"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting requirements.txt\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leverage Kaggle API for Subreddit Dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: confuse==1.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.0)\nRequirement already satisfied: icecream==2.1.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (2.1.1)\nRequirement already satisfied: plotly==5.3.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (5.3.1)\nRequirement already satisfied: kaleido==0.2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.2.1)\nRequirement already satisfied: scikit-surprise==1.1.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.1.1)\nRequirement already satisfied: kaggle==1.5.12 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (1.5.12)\nRequirement already satisfied: pyyaml in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from confuse==1.6.0->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: pygments>=2.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from icecream==2.1.1->-r requirements.txt (line 2)) (2.10.0)\nRequirement already satisfied: asttokens>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from icecream==2.1.1->-r requirements.txt (line 2)) (2.0.5)\nRequirement already satisfied: colorama>=0.3.9 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from icecream==2.1.1->-r requirements.txt (line 2)) (0.4.4)\nRequirement already satisfied: executing>=0.3.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from icecream==2.1.1->-r requirements.txt (line 2)) (0.8.2)\nRequirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from plotly==5.3.1->-r requirements.txt (line 3)) (1.16.0)\nRequirement already satisfied: tenacity>=6.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from plotly==5.3.1->-r requirements.txt (line 3)) (8.0.1)\nRequirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-surprise==1.1.1->-r requirements.txt (line 5)) (0.14.1)\nRequirement already satisfied: numpy>=1.11.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-surprise==1.1.1->-r requirements.txt (line 5)) (1.18.5)\nRequirement already satisfied: scipy>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-surprise==1.1.1->-r requirements.txt (line 5)) (1.5.2)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle==1.5.12->-r requirements.txt (line 6)) (4.62.3)\nRequirement already satisfied: urllib3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle==1.5.12->-r requirements.txt (line 6)) (1.25.11)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle==1.5.12->-r requirements.txt (line 6)) (2021.10.8)\nRequirement already satisfied: python-slugify in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle==1.5.12->-r requirements.txt (line 6)) (5.0.2)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle==1.5.12->-r requirements.txt (line 6)) (2.26.0)\nRequirement already satisfied: python-dateutil in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle==1.5.12->-r requirements.txt (line 6)) (2.8.2)\nRequirement already satisfied: text-unidecode>=1.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-slugify->kaggle==1.5.12->-r requirements.txt (line 6)) (1.3)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->kaggle==1.5.12->-r requirements.txt (line 6)) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->kaggle==1.5.12->-r requirements.txt (line 6)) (2.0.7)\n"
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import confuse\r\n",
        "\r\n",
        "config = confuse.Configuration('redditrec',__name__)\r\n",
        "config.set_file('config-subreddit.yaml')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639895036876
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ```mkdir ~/.kaggle```\r\n",
        "2. upload ```kaggle.json``` and ```mv <source> ~/.kaggle/kaggle.json```\r\n",
        "3. ```chmod 600 ~/.kaggle/kaggle.json```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "k_api = KaggleApi()\n",
        "k_api.authenticate()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1639895050854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from icecream import ic\n",
        "import os\n",
        "\n",
        "data_folder_name = config['folder_paths']['data_folder_name'].get()\n",
        "if not (os.path.exists(data_folder_name)):\n",
        "    os.mkdir(data_folder_name)\n",
        "os.chdir(data_folder_name)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639895052699
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference = k_api.datasets_list(search='Subreddit Recommender')[0]['ref']\n",
        "reference = 'timschaum/subreddit-recommender'\n",
        "ic(reference);\n",
        "k_api.dataset_download_files(reference)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| reference: 'timschaum/subreddit-recommender'\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1639890905640
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zf_name = reference.split('/')[1] + '.zip'\n",
        "zf = ZipFile(zf_name)\n",
        "zf.extractall()\n",
        "zf.close()"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1639890924692
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_dir = os.path.dirname(os.getcwd())\n",
        "os.chdir(original_dir)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639895058717
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "from IPython.display import display\r\n",
        "from icecream import ic\r\n",
        "\r\n",
        "subreddit_df = pd.read_csv(os.path.join(data_folder_name,'reddit_user_data_count.csv'),nrows=int(5e4))\r\n",
        "# limiting nrows to 50000 for compute limitations\r\n",
        "display(subreddit_df.head())\r\n",
        "ic(subreddit_df.shape);"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                   user        subreddit  count\n0  ------Username------        AskReddit     20\n1  ------Username------            Barca      9\n2  ------Username------             FIFA      4\n3  ------Username------              MMA      5\n4  ------Username------  RioGrandeValley      3",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>subreddit</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>------Username------</td>\n      <td>AskReddit</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>------Username------</td>\n      <td>Barca</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>------Username------</td>\n      <td>FIFA</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>------Username------</td>\n      <td>MMA</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>------Username------</td>\n      <td>RioGrandeValley</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| subreddit_df.shape: (50000, 3)\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639895060795
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\r\n",
        "\r\n",
        "plot_output_folder = config['folder_paths']['plot_output_folder_name'].get()\r\n",
        "if not os.path.exists(plot_output_folder):\r\n",
        "    os.mkdir(plot_output_folder)\r\n",
        "group_col, count_col, top_n = 'subreddit', 'count', 5\r\n",
        "hist_df = subreddit_df.groupby(by=[group_col])[count_col].sum()\\\r\n",
        ".sort_values(ascending=False)[0:top_n]\r\n",
        "hist_trace = go.Bar(\r\n",
        "    x = hist_df.index,\r\n",
        "    text = [f'{val:.1f}' for val in hist_df.values],\r\n",
        "    textposition = 'auto',\r\n",
        "    textfont = dict(color='blue'),\r\n",
        "    y = hist_df.values\r\n",
        ")\r\n",
        "hist_layout = dict(\r\n",
        "    title = f'Distribution of Top {top_n} {group_col}',\r\n",
        "    xaxis = dict(title=f'{group_col}'),\r\n",
        "    yaxis = dict(title='count')\r\n",
        ")\r\n",
        "fig = go.Figure(data=[hist_trace],layout=hist_layout)\r\n",
        "fig.write_image(os.path.join(plot_output_folder,f\"top_{top_n}_eda.png\"))"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639895067045
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Azureml Workspace and Experiment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "import numpy as np\r\n",
        "import logging\r\n",
        "from azureml.core import Workspace, Dataset, Experiment, Environment, Run\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "experiment_name = config['azureml']['experiment_name'].get()\r\n",
        "experiment = Experiment(ws,name=experiment_name)\r\n",
        "env_name = config['azureml']['environment_name'].get()\r\n",
        "subreddit_env = Environment.from_conda_specification(name=env_name,file_path='./conda_dependencies.yml')"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639895090544
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = ws.get_default_datastore()\r\n",
        "dataset_name = config['azureml']['dataset_name'].get()\r\n",
        "dataset = Dataset.Tabular.register_pandas_dataframe(\r\n",
        "    subreddit_df,\r\n",
        "    datastore,\r\n",
        "    dataset_name,\r\n",
        "    show_progress=True\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to managed-dataset/fe001378-4c3b-4426-b466-78b69fb8fa4a/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639895107004
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test registered dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subreddit_df = Dataset.get_by_name(ws,name=dataset_name).to_pandas_dataframe()\r\n",
        "display(subreddit_df.head())"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                   user        subreddit  count\n0  ------Username------        AskReddit     20\n1  ------Username------            Barca      9\n2  ------Username------             FIFA      4\n3  ------Username------              MMA      5\n4  ------Username------  RioGrandeValley      3",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>subreddit</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>------Username------</td>\n      <td>AskReddit</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>------Username------</td>\n      <td>Barca</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>------Username------</td>\n      <td>FIFA</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>------Username------</td>\n      <td>MMA</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>------Username------</td>\n      <td>RioGrandeValley</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639895112681
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit models leveraging **scikit-surprise**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import (\r\n",
        "    # collaborative filtering models\r\n",
        "    NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans,\r\n",
        "    KNNWithZScore, KNNBaseline, SVD, SVDpp, SlopeOne, CoClustering,\r\n",
        "    # utility functions\r\n",
        "    Reader, Dataset\r\n",
        ")\r\n",
        "from surprise.accuracy import (\r\n",
        "    rmse, mae, mse, fcp\r\n",
        ")\r\n",
        "from surprise.model_selection import train_test_split\r\n",
        "\r\n",
        "random_state = config['surprise']['random_state'].get()\r\n",
        "verbose_bool = config['surprise']['verbose_bool'].get()\r\n",
        "test_size = config['surprise']['test_size'].get()\r\n",
        "max_count, min_count = max(subreddit_df['count']), min(subreddit_df['count'])\r\n",
        "reader = Reader(rating_scale=(min_count,max_count))\r\n",
        "full_data = Dataset.load_from_df(subreddit_df,reader)\r\n",
        "train_data, test_data = train_test_split(full_data,test_size=test_size)\r\n",
        "model_list = [\r\n",
        "    NormalPredictor(),\r\n",
        "    BaselineOnly(verbose=verbose_bool),\r\n",
        "    KNNBasic(k=40, min_k=1, verbose=verbose_bool),\r\n",
        "    KNNWithMeans(k=40, min_k=1, verbose=verbose_bool),\r\n",
        "    KNNWithZScore(k=40, min_k=1, verbose=verbose_bool),\r\n",
        "    KNNBaseline(k=40, min_k=1, verbose=verbose_bool),\r\n",
        "    SVD(n_factors=100, n_epochs=20, biased=True, init_mean=0,\r\n",
        "    init_std_dev=.1, lr_all=.005,reg_all=.02, lr_bu=None, lr_bi=None, \r\n",
        "    lr_pu=None, lr_qi=None,reg_bu=None, reg_bi=None, reg_pu=None, reg_qi=None,\r\n",
        "    random_state=random_state, verbose=verbose_bool),\r\n",
        "    SVDpp(n_factors=20, n_epochs=20, init_mean=0, init_std_dev=.1,\r\n",
        "    lr_all=.007, reg_all=.02, lr_bu=None, lr_bi=None, lr_pu=None,\r\n",
        "    lr_qi=None, lr_yj=None, reg_bu=None, reg_bi=None, reg_pu=None,\r\n",
        "    reg_qi=None, reg_yj=None, random_state=None, verbose=verbose_bool),\r\n",
        "    SlopeOne(),\r\n",
        "    CoClustering(n_cltr_u=3, n_cltr_i=3, n_epochs=20, random_state=random_state,\r\n",
        "    verbose=verbose_bool)\r\n",
        "]\r\n",
        "benchmark = []\r\n",
        "for model in model_list:\r\n",
        "    model.fit(train_data)\r\n",
        "    y_pred = model.test(test_data)\r\n",
        "    model_dict = {\r\n",
        "        'model': str(model).split(' ')[0].split('.')[-1],\r\n",
        "        'rmse': rmse(y_pred,verbose=verbose_bool),\r\n",
        "        'mse': mse(y_pred,verbose=verbose_bool),\r\n",
        "        'mae': mae(y_pred,verbose=verbose_bool),\r\n",
        "        'fcp': fcp(y_pred,verbose=verbose_bool)\r\n",
        "    }\r\n",
        "    benchmark.append(model_dict)\r\n",
        "benchmark_df = pd.DataFrame(benchmark)\r\n",
        "display(benchmark_df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "             model        rmse            mse         mae       fcp\n0  NormalPredictor   59.838843    3580.687149   29.929177  0.433464\n1     BaselineOnly   47.308215    2238.067234   14.010158  0.498550\n2         KNNBasic   54.200222    2937.664116   14.883123  0.522803\n3     KNNWithMeans   54.604941    2981.699585   16.603188  0.427097\n4    KNNWithZScore   57.312380    3284.708916   16.433479  0.487474\n5      KNNBaseline   53.918238    2907.176366   15.389900  0.433184\n6              SVD  989.903430  979908.801000  988.690172  0.000000\n7            SVDpp  989.903430  979908.801000  988.690172  0.000000\n8         SlopeOne   50.222751    2522.324678   15.524001  0.491153\n9     CoClustering   64.915045    4213.963032   17.734558  0.427848",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>rmse</th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>fcp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NormalPredictor</td>\n      <td>59.838843</td>\n      <td>3580.687149</td>\n      <td>29.929177</td>\n      <td>0.433464</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BaselineOnly</td>\n      <td>47.308215</td>\n      <td>2238.067234</td>\n      <td>14.010158</td>\n      <td>0.498550</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNNBasic</td>\n      <td>54.200222</td>\n      <td>2937.664116</td>\n      <td>14.883123</td>\n      <td>0.522803</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNNWithMeans</td>\n      <td>54.604941</td>\n      <td>2981.699585</td>\n      <td>16.603188</td>\n      <td>0.427097</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNNWithZScore</td>\n      <td>57.312380</td>\n      <td>3284.708916</td>\n      <td>16.433479</td>\n      <td>0.487474</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNNBaseline</td>\n      <td>53.918238</td>\n      <td>2907.176366</td>\n      <td>15.389900</td>\n      <td>0.433184</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SVD</td>\n      <td>989.903430</td>\n      <td>979908.801000</td>\n      <td>988.690172</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SVDpp</td>\n      <td>989.903430</td>\n      <td>979908.801000</td>\n      <td>988.690172</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>SlopeOne</td>\n      <td>50.222751</td>\n      <td>2522.324678</td>\n      <td>15.524001</td>\n      <td>0.491153</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CoClustering</td>\n      <td>64.915045</td>\n      <td>4213.963032</td>\n      <td>17.734558</td>\n      <td>0.427848</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639895421846
        }
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "961fee12dacd1373a18d1b8aa10b592e6d87f8713f5cf1b9a971545ca71e0b61"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}